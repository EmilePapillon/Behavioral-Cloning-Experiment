{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# vim: tabstop=8 expandtab shiftwidth=4 softtabstop=4:\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import os\n",
    "import sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Dropout, Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Data augmentation functions definitions\n",
    "def do_nothing(image,angle):\n",
    "    return image, angle\n",
    "\n",
    "def grayscale(image, angle):\n",
    "    gray = cv2.cvtColor(np.copy(image), cv2.COLOR_RGB2GRAY)\n",
    "    return cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB), angle\n",
    "\n",
    "def mirror(image, angle): \n",
    "    return np.fliplr(np.copy(image)), -angle\n",
    "\n",
    "def random_brightness(image, angle):\n",
    "    image1 = cv2.cvtColor(np.copy(image),cv2.COLOR_RGB2HSV)\n",
    "    random_bright = 0.8 + 0.4*(2*np.random.uniform()-1.0)    \n",
    "    image1[:,:,2] = image1[:,:,2]*random_bright\n",
    "    image1 = cv2.cvtColor(image1,cv2.COLOR_HSV2RGB)\n",
    "    return image1, angle\n",
    "\n",
    "def random_translation(img, angle):\n",
    "    tx_range,ty_range = 64,64\n",
    "    rows,cols,ch = img.shape\n",
    "    p=10 #pad the image (reflect the boundary)\n",
    "    tr_x = tx_range*np.random.uniform()-tx_range/2 #random number between -tx_range and +tx_range\n",
    "    tr_y = ty_range*np.random.uniform()-ty_range/2\n",
    "    #tr_y=-5\n",
    "    Trans_M = np.float32([[1,0,tr_x],[0,1,tr_y]])\n",
    "    wrap = cv2.copyMakeBorder(img,p,p,p,p,0) #pads image with 10px uniform border\n",
    "    img = cv2.warpAffine(wrap,Trans_M,(cols,rows))\n",
    "    #img = img[p:p+cols,p:p+rows]\n",
    "    \n",
    "    new_angle = angle + tr_x * 3.75e-4\n",
    "    return img, new_angle \n",
    "\n",
    "#return a list of tuples, each tuple containing path and angle for a training image, with the list of methods appended\n",
    "def make_reference_list(methods_index, data, offset=0.2):\n",
    "    paths= data.values[:,np.array([0,1,2])].reshape(-1) #flattened list containing center, left, right images paths\n",
    "    angles = np.array([[center, left, right] for center, left, right in zip(data.values[:,3], data.values[:,3]+offset, data.values[:,3]-offset)]).reshape(-1) #flattened list of corresponding angles\n",
    "    return [{'path':'../data/IMG/'+path.split('/')[-1], 'angle': angle, 'methods': methods_index} for path,angle in zip(paths,angles)]\n",
    "\n",
    "#picks a random element out of array, return the element and the updated numpy array\n",
    "def pick(numpy_array,index):\n",
    "    return numpy_array[index], np.delete(numpy_array, index)\n",
    "\n",
    "# the logic for making batches\n",
    "def batch_generator(training_data_reference, methods, batch_size = 32):\n",
    "    #define a list of transformations for each image in the data\n",
    "    while True:\n",
    "        \n",
    "        restart_flag = False\n",
    "        num_samples = len(training_data_reference)\n",
    "\n",
    "        while True:\n",
    "\n",
    "            for offset in range(0, num_samples, batch_size):\n",
    "\n",
    "                # get the next batch images\n",
    "                batch_samples = training_data_reference[offset:offset+batch_size]\n",
    "                X_batch, y_batch = np.empty((batch_size, 160 ,320, 3), dtype = np.uint8), np.empty(batch_size)\n",
    "\n",
    "                #for each image in batch...\n",
    "                for idx in range(len(batch_samples)):                 \n",
    "\n",
    "                    #pick the method and refresh the data reference\n",
    "                    image_path = batch_samples[idx]['path']\n",
    "                    image = cv2.imread(image_path)\n",
    "                    angle = batch_samples[idx]['angle']\n",
    "                    num_methods_left = len(batch_samples[idx]['methods'])\n",
    "\n",
    "                    #apply a random method and remove it from the list of methods for that datapoint\n",
    "                    try:\n",
    "                        random_int = np.random.randint(num_methods_left)\n",
    "                        method_index,training_data_reference[offset+idx]['methods'] = pick(batch_samples[idx]['methods'], random_int)\n",
    "                        method = methods[method_index]\n",
    "                    except ValueError: \n",
    "                        #method = do_nothing\n",
    "                        restart_flag = True\n",
    "                        break\n",
    "                    # get image and angle from calling selected method\n",
    "                    X_batch[idx], y_batch[idx] = method(image,angle)\n",
    "\n",
    "                if restart_flag: break\n",
    "\n",
    "                yield X_batch, y_batch\n",
    "\n",
    "data_file = '../data/driving_log.csv'\n",
    "data = pd.read_csv(data_file, header= None, names = ['center', 'left', 'right', 'steering_angle', 'x','y','z'])\n",
    "\n",
    "#list all the possible augmentation methods here\n",
    "methods = [grayscale, mirror, random_brightness,do_nothing]\n",
    "#methods = [grayscale, mirror, random_brightness,random_translation,do_nothing]\n",
    "\n",
    "methods_index = np.array(range(len(methods)))\n",
    "\n",
    "left_right_images_offset = 0.2 #angle offset for left and right images in radians\n",
    "training_data_reference = shuffle(make_reference_list(methods_index,data,offset=left_right_images_offset))\n",
    "\n",
    "train_samples, validation_samples = train_test_split(training_data_reference, test_size= 0.2)\n",
    "\n",
    "train_generator = batch_generator(train_samples , methods ,batch_size=32)\n",
    "validation_generator = batch_generator(validation_samples ,methods ,  batch_size=32)\n",
    "\n",
    "row, col, ch = 160, 320, 3  \n",
    "#model\n",
    "model = Sequential()\n",
    "model.add(Cropping2D(cropping = ((70,25),(0,0)),input_shape=(row,col,ch)))\n",
    "model.add(Lambda(lambda x: (x-128)/128))\n",
    "model.add(Conv2D(24, (5, 5), padding=\"same\", activation=\"elu\", strides=(2, 2)))\n",
    "model.add(Conv2D(36, (5, 5), padding=\"same\", activation=\"elu\", strides=(2, 2)))\n",
    "model.add(Conv2D(48, (5, 5), padding=\"same\", activation=\"elu\", strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", activation=\"elu\"))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", activation=\"elu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120))\n",
    "model.add(Dense(84))\n",
    "model.add(Dense(1))\n",
    "\n",
    "#train\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "#If the above code throw exceptions, try : \n",
    "history_object = model.fit_generator(train_generator, steps_per_epoch= len(train_samples)*len(methods),\n",
    "validation_data=validation_generator, validation_steps=len(validation_samples)*len(methods), epochs=3, verbose = 1)\n",
    "\n",
    "model.save('../model.h5')\n",
    "\n",
    "\n",
    "#This is to display training / validation losses\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "fig= plt.figure()\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "#plt.show()\n",
    "plt.savefig('../loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = next(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
