{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23268, 3)\n",
      "(5820, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:94: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:97: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:104: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:111: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "23268/23268 [==============================] - 1850s 79ms/step - loss: 0.0071 - val_loss: 0.0152\n",
      "Epoch 2/5\n",
      "23268/23268 [==============================] - 1842s 79ms/step - loss: 0.0022 - val_loss: 0.0161\n",
      "Epoch 3/5\n",
      "23268/23268 [==============================] - 1841s 79ms/step - loss: 0.0016 - val_loss: 0.0142\n",
      "Epoch 4/5\n",
      "23268/23268 [==============================] - 1836s 79ms/step - loss: 0.0014 - val_loss: 0.0147\n",
      "Epoch 5/5\n",
      "23268/23268 [==============================] - 1837s 79ms/step - loss: 0.0012 - val_loss: 0.0139\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# vim: tabstop=8 expandtab shiftwidth=4 softtabstop=4:\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import os\n",
    "import sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, Cropping2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lines = []\n",
    "with open('../data/driving_log.csv') as csvfile:\n",
    "\treader = csv.reader(csvfile)\n",
    "\tfor line in reader:\n",
    "\t\tlines.append(line)\n",
    "\n",
    "#returns a numpy array that is a copy of the input array with a new row of zeros at its end\n",
    "def appendEmptyRow(array):\n",
    "\t__array = np.empty((array.shape[0], array.shape[1]+1),dtype=np.dtype('<U128')) #empty array of unicode 128 character strings, little endian\n",
    "\t__array[:,0:array.shape[1]] = array\n",
    "\treturn __array\n",
    "\n",
    "#augments and pre-processes (shuffle, crop)  the datai\n",
    "#reformats the data : [img_path angle]\n",
    "def preprocess(samples):\n",
    "\t#TODO calculate a more accurate correction factor\n",
    "\tcorrection_factor = 0.2\n",
    "\tsamples=np.array(samples)\n",
    "\t#augment with left and right images\n",
    "\tsamples_center = appendEmptyRow(samples[:,np.array([0,3])]) #row of zeros is appended to indicate that this is not a flipped image\n",
    "\tsamples_left = appendEmptyRow(samples[:,np.array([1,3])])\n",
    "\tsamples_left[:,1] = [str(float(sample_left) + correction_factor) for sample_left in samples_left[:,1]] #slightly change the steering angle label for the left camera e\n",
    "\tsamples_right = appendEmptyRow(samples[:,np.array([2,3])])\n",
    "\tsamples_right[:,1] = [str(float(sample_right) - correction_factor) for sample_right in samples_right[:,1]] \n",
    "\tsamples_mirror = samples_center\n",
    "\tsamples_mirror[:,1] = [str(float(sample_mirror) *-1) for sample_mirror in samples_mirror[:,1]] #flip the angle\n",
    "\tsamples_mirror[:,-1] = 'f' #this one is flipped\t\n",
    "\t\n",
    "\t#appending in a loop was the only way that worked\n",
    "\tpreprocessed_samples = samples_center\n",
    "\tarrays_to_append = [samples_left,samples_right,samples_mirror]\n",
    "\tfor array in arrays_to_append : \n",
    "\t\tpreprocessed_samples = np.append(preprocessed_samples, array, axis=0) \n",
    "\tprint(preprocessed_samples.shape)\n",
    "\n",
    "\treturn shuffle(preprocessed_samples)\n",
    "\n",
    "\n",
    "train_samples, validation_samples = train_test_split(lines, test_size= 0.2)\n",
    "\t\n",
    "#TODO :make sure samples are shuffled somewhere in the process\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "        \n",
    "\tnum_samples = len(samples)\n",
    "\twhile 1: # Loop forever so the generator never terminates\n",
    "\t\tfor offset in range(0, num_samples, batch_size):\n",
    "\t\t\tbatch_samples = samples[offset:offset+batch_size]\n",
    "\t\t\timages = []\n",
    "\t\t\tangles = []\n",
    "\t\t\t\n",
    "\t\t\tfor batch_sample in batch_samples:\n",
    "\t\t\t\tname = '../data/IMG/'+batch_sample[0].split('/')[-1]\n",
    "\t\t\t\timage = cv2.imread(name)\n",
    "\t\t\t\tangle = float(batch_sample[1])\n",
    "\t\t\t\tif bool(batch_sample[2]): \n",
    "\t\t\t\t\timage = np.fliplr(image) # if this is one of the inverted samples, we must now invert the image\n",
    "\t\t\t\t\timages.append(image)\n",
    "\t\t\t\t\tangles.append(angle)\n",
    "\t\t\tX_train = np.array(images)\n",
    "\t\t\ty_train = np.array(angles)\n",
    "\t\t\tyield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "preprocessed_train_samples = preprocess(train_samples)\n",
    "preprocessed_validation_samples = preprocess(validation_samples) \n",
    "train_generator = generator(preprocessed_train_samples , batch_size=24)\n",
    "validation_generator = generator(preprocessed_validation_samples , batch_size=24)\n",
    "ch, row, col = 3, 160, 320  \n",
    "\n",
    "#model\n",
    "model = Sequential()\n",
    "model.add(Cropping2D(cropping = ((70,25),(0,0)),input_shape=(row,col,ch)))\n",
    "model.add(Lambda(lambda x: (x-128)/128))\n",
    "model.add(Convolution2D(16,3,3, \n",
    "\tactivation='relu', \n",
    "\tborder_mode= 'same'))\n",
    "model.add(Convolution2D(16,3,3,\n",
    "\tactivation='relu',\n",
    "\tborder_mode='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Convolution2D(24,3,3, \n",
    "\tactivation='relu',\n",
    "\tborder_mode='same'))\n",
    "model.add(Convolution2D(24,3,3, \n",
    "\tactivation='relu',\n",
    "\tborder_mode='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Convolution2D(32,3,3, \n",
    "\tactivation='relu',\n",
    "\tborder_mode='same'))\n",
    "model.add(Convolution2D(32,3,3, \n",
    "\tactivation='relu',\n",
    "\tborder_mode='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120))\n",
    "model.add(Dense(84))\n",
    "model.add(Dense(1))\n",
    "\n",
    "#train\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "#If the above code throw exceptions, try : \n",
    "history_object = model.fit_generator(train_generator, steps_per_epoch= len(preprocessed_train_samples),\n",
    "validation_data=validation_generator, validation_steps=len(preprocessed_validation_samples), epochs=5, verbose = 1)\n",
    "\n",
    "model.save('../model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history_object' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-80aff3b3e820>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#This is to display training / validation losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m### print the keys contained in the history object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m### plot the training and validation loss for each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history_object' is not defined"
     ]
    }
   ],
   "source": [
    "#This is to display training / validation losses\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
